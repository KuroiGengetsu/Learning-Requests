# 爬取名人名言

本文主要是从 [名人名言网站](http://www.mingyannet.com/) 爬取名人名言， 旨在练习 `python` 的 `requests` 库 与 *built-in* 的 `re` 模块

## 简易教程

偶然发现这个网站, 比较适合拿来练手, 意图很简单, 那就是先从主页获得各种各样的话题, 接着访问这些话题的连接, 然后将这些名人名言保存到本地, 这是一种最简单的爬虫模式.

### Overview

这个小项目一共有四个文件:

	* `main.py`: 主函数定义在这里, 每次只需要执行这个文件就可以
	
	* `celebrity_quotes.py`: 一些主要的函数, 可以说它是整个项目的核心部分
	
	* `quotes.py`: 定义了一个类 `Quotes`, 用来存放爬下来的 **某个话题** 的名言
	
	* `settings.py`: 存放一些全局变量, 毕竟是小项目, 所以变量很少.

`files` 文件夹下存放爬下来的名言, 可以先预览下

### 分析

以上来肯定是先要分析一波, 第一次点开这个网站就知道这个网站很容易拿来练习

首页上放了一堆 **话题**, 并且都是**链接**的形式, 他们的格式都是类似的, 出入不大, 具体情况到时候可以通过分析源代码来了解

随便点开一个链接, 里面的名言格式也比较工整, 猜测多数都可以通过一个表达式来获得, 当然现在只是分析, 写代码以及测试都是后边的事情, 现在不用关心, 只需要决定主要流程即可

拉到网页的最下面, 有 **第二页**, **第三夜**, 点击之后, 发现与第一页并不是同一个话题, 回到主页发现有相同的话题, 而且内容都一样, 因此, **这是一个假的页数**, 所以这下就省劲了, 不用写翻页的代码了, 如果要写的话, 不小心就会陷入无尽的循环(如果不定义 **链接池** 的话, 也就是不判断是否爬取过相同的网页, 很容易就死循环)

所以经过上面的分析, 需要做的任务就是:

    1. 通过 **主页** 获得 **话题** 与 **对应的链接**

	2. 访问这些链接并爬取 **名言**
	
	3. 将爬取到的名言通过 **话题** 归类
	
	4. 处理这些数据

